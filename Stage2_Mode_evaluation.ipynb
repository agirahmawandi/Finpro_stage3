{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "144335bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import joblib\n",
    "import os\n",
    "import sklearn\n",
    "import xgboost\n",
    "import optuna\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "21fedd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.13.2 | packaged by Anaconda, Inc. | (main, Feb  6 2025, 18:49:14) [MSC v.1929 64 bit (AMD64)]\n",
      "pandas: 2.2.3\n",
      "numpy: 2.2.5\n",
      "scikit-learn: 1.6.1\n",
      "xgboost: 3.0.1\n",
      "joblib: 1.5.1\n"
     ]
    }
   ],
   "source": [
    "print(\"Python:\", os.sys.version)\n",
    "print(\"pandas:\", pd.__version__)\n",
    "print(\"numpy:\", np.__version__)\n",
    "print(\"scikit-learn:\", sklearn.__version__)\n",
    "print(\"xgboost:\", xgboost.__version__)\n",
    "print(\"joblib:\", joblib.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725cce0d",
   "metadata": {},
   "source": [
    "## Environment dan Versi Library\n",
    "\n",
    "Notebook ini dijalankan menggunakan **Python 3.13.2 (Anaconda)** dengan versi library sebagai berikut:\n",
    "\n",
    "| Library       | Version  |\n",
    "|---------------|----------|\n",
    "| pandas        | 2.2.3    |\n",
    "| numpy         | 2.2.5    |\n",
    "| scikit-learn  | 1.6.1    |\n",
    "| xgboost       | 3.0.1    |\n",
    "| joblib        | 1.5.1    |\n",
    "\n",
    "Untuk mereplikasi environment ini, jalankan:\n",
    "```bash\n",
    "pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "9da4c0fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   Age                  1500 non-null   int64  \n",
      " 1   Gender               1500 non-null   int64  \n",
      " 2   EducationLevel       1500 non-null   int64  \n",
      " 3   ExperienceYears      1500 non-null   int64  \n",
      " 4   PreviousCompanies    1500 non-null   int64  \n",
      " 5   DistanceFromCompany  1500 non-null   float64\n",
      " 6   InterviewScore       1500 non-null   int64  \n",
      " 7   SkillScore           1500 non-null   int64  \n",
      " 8   PersonalityScore     1500 non-null   int64  \n",
      " 9   RecruitmentStrategy  1500 non-null   int64  \n",
      " 10  HiringDecision       1500 non-null   int64  \n",
      "dtypes: float64(1), int64(10)\n",
      "memory usage: 129.0 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('dataset/recruitment_data.csv')\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d91a0d",
   "metadata": {},
   "source": [
    "## Convert data int to category "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "91e849a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_convert = [\"Gender\", \"EducationLevel\", \"RecruitmentStrategy\"]\n",
    "\n",
    "# ubah tipe data ke category\n",
    "df[cols_to_convert] = df[cols_to_convert].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "b42eeb56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1500 entries, 0 to 1499\n",
      "Data columns (total 11 columns):\n",
      " #   Column               Non-Null Count  Dtype   \n",
      "---  ------               --------------  -----   \n",
      " 0   Age                  1500 non-null   int64   \n",
      " 1   Gender               1500 non-null   category\n",
      " 2   EducationLevel       1500 non-null   category\n",
      " 3   ExperienceYears      1500 non-null   int64   \n",
      " 4   PreviousCompanies    1500 non-null   int64   \n",
      " 5   DistanceFromCompany  1500 non-null   float64 \n",
      " 6   InterviewScore       1500 non-null   int64   \n",
      " 7   SkillScore           1500 non-null   int64   \n",
      " 8   PersonalityScore     1500 non-null   int64   \n",
      " 9   RecruitmentStrategy  1500 non-null   category\n",
      " 10  HiringDecision       1500 non-null   int64   \n",
      "dtypes: category(3), float64(1), int64(7)\n",
      "memory usage: 98.7 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea9386c",
   "metadata": {},
   "source": [
    "##  Split Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "a26249dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukuran X_train: (1200, 10)\n",
      "Ukuran X_test : (300, 10)\n",
      "Ukuran y_train: (1200,)\n",
      "Ukuran y_test : (300,)\n",
      "Dataset berhasil disimpan ke 'train.csv' dan 'test.csv'\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(\"HiringDecision\", axis=1)  \n",
    "y = df[\"HiringDecision\"]\n",
    "\n",
    "# split data: 80% train, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(\"Ukuran X_train:\", X_train.shape)\n",
    "print(\"Ukuran X_test :\", X_test.shape)\n",
    "print(\"Ukuran y_train:\", y_train.shape)\n",
    "print(\"Ukuran y_test :\", y_test.shape)\n",
    "\n",
    "# gabungkan kembali X dan y agar sesuai dengan data awal\n",
    "train_set = pd.concat([X_train, y_train], axis=1)\n",
    "test_set = pd.concat([X_test, y_test], axis=1)\n",
    "\n",
    "# simpan ke CSV\n",
    "train_set.to_csv(\"dataset/train.csv\", index=False)\n",
    "test_set.to_csv(\"dataset/test.csv\", index=False)\n",
    "\n",
    "print(\"Dataset berhasil disimpan ke 'train.csv' dan 'test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81ed885",
   "metadata": {},
   "source": [
    "## Pipeline Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "948e95e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =====================\n",
    "# 1. Load data from CSV\n",
    "# =====================\n",
    "train_df = pd.read_csv(\"dataset/train.csv\")\n",
    "test_df = pd.read_csv(\"dataset/test.csv\")\n",
    "\n",
    "X_train = train_df.drop([\"HiringDecision\", \"Age\", \"DistanceFromCompany\", \"Gender\",'PreviousCompanies'], axis=1)\n",
    "y_train = train_df[\"HiringDecision\"]\n",
    "\n",
    "X_test = test_df.drop([\"HiringDecision\", \"Age\", \"DistanceFromCompany\", \"Gender\",'PreviousCompanies'], axis=1)\n",
    "y_test = test_df[\"HiringDecision\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "38391930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline preprocessing berhasil disimpan.\n",
      "Train shape: (1200, 10)\n",
      "Test shape : (300, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# =====================\n",
    "# 3. Preprocessing setup\n",
    "# =====================\n",
    "\n",
    "class DataCleaner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # 1. Drop duplicates\n",
    "        X = X.drop_duplicates()\n",
    "        \n",
    "        # 2. Missing value handling\n",
    "        for col in X.select_dtypes(include=[\"float\", \"int\"]).columns:\n",
    "            X[col] = X[col].fillna(X[col].median())   # numeric → median\n",
    "        for col in X.select_dtypes(include=[\"object\"]).columns:\n",
    "            X[col] = X[col].fillna(X[col].mode()[0]) # categorical → modus\n",
    "        \n",
    "        # 3. Outlier handling (IQR method pada numerical)\n",
    "        for col in X.select_dtypes(include=[\"float\", \"int\"]).columns:\n",
    "            Q1 = X[col].quantile(0.25)\n",
    "            Q3 = X[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower, upper = Q1 - 1.5*IQR, Q3 + 1.5*IQR\n",
    "            X[col] = np.where(X[col] < lower, lower,\n",
    "                              np.where(X[col] > upper, upper, X[col]))\n",
    "        \n",
    "        return X\n",
    "    \n",
    "# b. ExperienceYears → binning (junior/mid/senior)\n",
    "\n",
    "\n",
    "# a. EducationLevel → OH encode\n",
    "edu_pipeline = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "def bin_experience(x):\n",
    "    bins = np.array(x).astype(int).ravel()\n",
    "    labels = []\n",
    "    for v in bins:\n",
    "        if v <=2:\n",
    "            labels.append(\"Junior\")\n",
    "        elif v <=5:\n",
    "            labels.append(\"Mid\")\n",
    "        else:\n",
    "            labels.append(\"Senior\")\n",
    "    return np.array(labels).reshape(-1,1)\n",
    "\n",
    "exp_pipeline = Pipeline([\n",
    "    (\"binning\", FunctionTransformer(bin_experience, validate=False)),\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))  # one-hot encode hasil binning\n",
    "])\n",
    "\n",
    "# c. RecruitmentStrategy → one-hot encode\n",
    "recruitment_pipeline = Pipeline([\n",
    "    (\"onehot\", OneHotEncoder(drop=\"first\"))\n",
    "])\n",
    "\n",
    "# d. Numerical features → scaling\n",
    "num_features = [\"InterviewScore\", \"SkillScore\", \"PersonalityScore\"]\n",
    "num_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "# =====================\n",
    "# 4. ColumnTransformer\n",
    "# =====================\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"recruitment\", recruitment_pipeline, [\"RecruitmentStrategy\"]),\n",
    "        (\"education\", edu_pipeline, [\"EducationLevel\"]),\n",
    "        (\"experience\", exp_pipeline, [\"ExperienceYears\"]),\n",
    "        (\"num\", num_pipeline, num_features)\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "\n",
    "# Pipeline gabungan: cleaning + preprocessing\n",
    "full_pipeline = Pipeline([\n",
    "    (\"cleaning\", DataCleaner()),   # tahap cleaning\n",
    "    (\"preprocessing\", preprocessor) # tahap preprocessing (OH, scaling, dsb.)\n",
    "])\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "# Simpan pipeline preprocessing\n",
    "joblib.dump(preprocessor, \"preprocesor.pkl\")\n",
    "print(\"Pipeline preprocessing berhasil disimpan.\")\n",
    "\n",
    "# Transform data\n",
    "X_train_transformed = full_pipeline.fit_transform(X_train)\n",
    "X_test_transformed  = full_pipeline.transform(X_test)\n",
    "\n",
    "print(\"Train shape:\", X_train_transformed.shape)\n",
    "print(\"Test shape :\", X_test_transformed.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1a1937f",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10ace0",
   "metadata": {},
   "source": [
    "## Test to many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "6fcb2487",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "def evaluate_models(models, X_train, y_train, X_test, y_test, save_csv=True):\n",
    "    results = []\n",
    "\n",
    "    for name, model in models.items():\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # === TRAIN ===\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "        report_train = classification_report(y_train, y_train_pred, output_dict=True)\n",
    "        roc_auc_train = roc_auc_score(y_train, y_train_prob)\n",
    "\n",
    "        # === TEST ===\n",
    "        y_test_pred = model.predict(X_test)\n",
    "        y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "        report_test = classification_report(y_test, y_test_pred, output_dict=True)\n",
    "        roc_auc_test = roc_auc_score(y_test, y_test_prob)\n",
    "\n",
    "        # === Gabungkan semua metrik ===\n",
    "        metrics = {\n",
    "            \"Model\":               [name, name],  # supaya ada di Train & Test\n",
    "            \"Precision (class 1)\": [round(report_train[\"1\"][\"precision\"], 3), round(report_test[\"1\"][\"precision\"], 3)],\n",
    "            # \"Recall (class 1)\":    [round(report_train[\"1\"][\"recall\"], 3),    round(report_test[\"1\"][\"recall\"], 3)],\n",
    "            \"F1-score (class 1)\":  [round(report_train[\"1\"][\"f1-score\"], 3),  round(report_test[\"1\"][\"f1-score\"], 3)],\n",
    "            # \"Accuracy\":            [round(report_train[\"accuracy\"], 3),       round(report_test[\"accuracy\"], 3)],\n",
    "            \"ROC AUC\":             [round(roc_auc_train, 3),                  round(roc_auc_test, 3)]\n",
    "        }\n",
    "\n",
    "        df_metrics = pd.DataFrame(metrics, index=[\"Train\", \"Test\"])\n",
    "\n",
    "        # === Hitung Gap (%) hanya untuk kolom numerik ===\n",
    "        numeric_cols = df_metrics.select_dtypes(include=\"number\").columns\n",
    "        gap_values = ((df_metrics.loc[\"Train\", numeric_cols] - df_metrics.loc[\"Test\", numeric_cols])\n",
    "                      / df_metrics.loc[\"Train\", numeric_cols] * 100).round(2)\n",
    "\n",
    "        # tambahkan model di gap row\n",
    "        gap_row = pd.Series({col: gap_values.get(col, None) for col in df_metrics.columns} | {\"Model\": name},name=\"Gap (%)\")\n",
    "\n",
    "        # gap_row = pd.Series({col: gap_values.get(col, None) for col in df_metrics.columns}, name=\"Gap (%)\")\n",
    "        gap_row[\"Model\"] = name\n",
    "\n",
    "        # gabungkan\n",
    "        df_metrics = pd.concat([df_metrics, gap_row.to_frame().T])\n",
    "\n",
    "        # Reset index agar ada kolom Dataset\n",
    "        df_metrics = df_metrics.reset_index().rename(columns={\"index\": \"Dataset\"})\n",
    "\n",
    "          # Hanya ambil baris Test & Gap\n",
    "        df_metrics = df_metrics[df_metrics[\"Dataset\"].isin([\"Test\", \"Gap (%)\"])]\n",
    "\n",
    "        # Urutkan kolom: Model dulu\n",
    "        cols = [\"Model\", \"Dataset\"] + [c for c in df_metrics.columns if c not in [\"Model\", \"Dataset\"]]\n",
    "        df_metrics = df_metrics[cols]\n",
    "\n",
    "        results.append(df_metrics)\n",
    "\n",
    "    # Gabungkan semua hasil\n",
    "    final_results = pd.concat(results, ignore_index=True)\n",
    "\n",
    "    # === Ranking berdasarkan ROC AUC Test ===\n",
    "    ranking = (\n",
    "        final_results[final_results[\"Dataset\"] == \"Test\"]\n",
    "        .sort_values(by=\"ROC AUC\", ascending=False)[[\"Model\", \"ROC AUC\"]]\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    ranking.index = ranking.index + 1  # biar mulai dari 1\n",
    "\n",
    "    return final_results, ranking\n",
    "\n",
    "\n",
    "    # # Simpan ke CSV kalau diminta\n",
    "    # if save_csv:\n",
    "    #     final_results.to_csv(\"evaluation_results.csv\", index=False)\n",
    "    #     ranking.to_csv(\"model_ranking.csv\", index=False)\n",
    "    #     print(\"✅ Hasil evaluasi semua model disimpan ke evaluation_results.csv\")\n",
    "    #     print(\"✅ Ranking model (berdasarkan ROC AUC Test) disimpan ke model_ranking.csv\")\n",
    "\n",
    "    # return final_results, ranking\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5ecc665f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 Hasil Evaluasi Model:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Precision (class 1)</th>\n",
       "      <th>F1-score (class 1)</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.814</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>-1.058201</td>\n",
       "      <td>0.610501</td>\n",
       "      <td>0.539374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNN</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>7.590759</td>\n",
       "      <td>14.965986</td>\n",
       "      <td>5.475207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.835</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>16.5</td>\n",
       "      <td>23.3</td>\n",
       "      <td>17.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.948</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>5.2</td>\n",
       "      <td>14.014014</td>\n",
       "      <td>6.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.961</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>0.825593</td>\n",
       "      <td>8.280255</td>\n",
       "      <td>3.516029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>-4.694323</td>\n",
       "      <td>2.880184</td>\n",
       "      <td>1.798942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>9.440994</td>\n",
       "      <td>6.983655</td>\n",
       "      <td>3.218391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Model  Dataset Precision (class 1) F1-score (class 1)  \\\n",
       "0   Logistic Regression     Test               0.764              0.814   \n",
       "1   Logistic Regression  Gap (%)           -1.058201           0.610501   \n",
       "2                   KNN     Test                0.84               0.75   \n",
       "3                   KNN  Gap (%)            7.590759          14.965986   \n",
       "4         Decision Tree     Test               0.835              0.767   \n",
       "5         Decision Tree  Gap (%)                16.5               23.3   \n",
       "6         Random Forest     Test               0.948              0.859   \n",
       "7         Random Forest  Gap (%)                 5.2          14.014014   \n",
       "8     Gradient Boosting     Test               0.961              0.864   \n",
       "9     Gradient Boosting  Gap (%)            0.825593           8.280255   \n",
       "10                  SVM     Test               0.959              0.843   \n",
       "11                  SVM  Gap (%)           -4.694323           2.880184   \n",
       "12          Naive Bayes     Test               0.729              0.626   \n",
       "13          Naive Bayes  Gap (%)            9.440994           6.983655   \n",
       "14              XGBoost     Test                0.91               0.83   \n",
       "15              XGBoost  Gap (%)                 9.0               17.0   \n",
       "\n",
       "     ROC AUC  \n",
       "0      0.922  \n",
       "1   0.539374  \n",
       "2      0.915  \n",
       "3   5.475207  \n",
       "4      0.823  \n",
       "5       17.7  \n",
       "6      0.939  \n",
       "7        6.1  \n",
       "8      0.933  \n",
       "9   3.516029  \n",
       "10     0.928  \n",
       "11  1.798942  \n",
       "12     0.842  \n",
       "13  3.218391  \n",
       "14     0.928  \n",
       "15       7.2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🏆 Ranking Model berdasarkan ROC AUC (Test):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>ROC AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVM</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model ROC AUC\n",
       "1        Random Forest   0.939\n",
       "2    Gradient Boosting   0.933\n",
       "3                  SVM   0.928\n",
       "4              XGBoost   0.928\n",
       "5  Logistic Regression   0.922\n",
       "6                  KNN   0.915\n",
       "7          Naive Bayes   0.842\n",
       "8        Decision Tree   0.823"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, random_state=42,class_weight=\"balanced\"),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"SVM\": SVC(probability=True, random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        eval_metric=\"logloss\",\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "# ==== Panggil fungsi ====\n",
    "final_results, ranking = evaluate_models(models, X_train_transformed, y_train, X_test_transformed, y_test)\n",
    "\n",
    "print(\"\\n📊 Hasil Evaluasi Model:\")\n",
    "display(final_results)\n",
    "\n",
    "print(\"\\n🏆 Ranking Model berdasarkan ROC AUC (Test):\")\n",
    "display(ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05488936",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning untuk random forest dan gradient boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5310c8d9",
   "metadata": {},
   "source": [
    "## Random forest , Gradient Boosting & XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "42dda5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# Fungsi Evaluasi Model (Train vs Test)\n",
    "# =========================================\n",
    "def evaluate_train_test(model, X_train, y_train, X_test, y_test, model_name=\"Model\"):\n",
    "    # Prediksi Train\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_train_prob = model.predict_proba(X_train)[:, 1]\n",
    "\n",
    "    # Prediksi Test\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    y_test_prob = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Hasil Train\n",
    "    train_results = {\n",
    "        \"Accuracy\": accuracy_score(y_train, y_train_pred),\n",
    "        \"Precision\": precision_score(y_train, y_train_pred),\n",
    "        \"Recall\": recall_score(y_train, y_train_pred),\n",
    "        \"F1-Score\": f1_score(y_train, y_train_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_train, y_train_prob)\n",
    "    }\n",
    "\n",
    "    # Hasil Test\n",
    "    test_results = {\n",
    "        \"Accuracy\": accuracy_score(y_test, y_test_pred),\n",
    "        \"Precision\": precision_score(y_test, y_test_pred),\n",
    "        \"Recall\": recall_score(y_test, y_test_pred),\n",
    "        \"F1-Score\": f1_score(y_test, y_test_pred),\n",
    "        \"ROC-AUC\": roc_auc_score(y_test, y_test_prob)\n",
    "    }\n",
    "\n",
    "    # Gap (%)\n",
    "    gap_results = {m: 100 * (train_results[m] - test_results[m]) for m in train_results}\n",
    "\n",
    "    # Buat DataFrame untuk tampilan tabel\n",
    "    df_results = pd.DataFrame([\n",
    "        {\"Model\": model_name, \"Dataset\": \"Train\", **train_results},\n",
    "        {\"Model\": model_name, \"Dataset\": \"Test\", **test_results},\n",
    "        {\"Model\": model_name, \"Dataset\": \"Gap (%)\", **gap_results},\n",
    "    ])\n",
    "\n",
    "    return df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "f8fb1618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (Random Forest) =====\n",
      "Best Hyperparameter: {'n_estimators': 400, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'max_depth': 10, 'bootstrap': True}\n",
      "Best F1 Score : 0.8600095155218114\n",
      "\n",
      "Result Model evaluation Train vs Test:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.965833</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.943135</td>\n",
       "      <td>0.997916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.935120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1.317307</td>\n",
       "      <td>11.827957</td>\n",
       "      <td>7.254630</td>\n",
       "      <td>6.279544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Model  Dataset  Accuracy  Precision     Recall  F1-Score   ROC-AUC\n",
       "0  Random Forest    Train  0.965833   0.974212   0.913978  0.943135  0.997916\n",
       "1  Random Forest     Test  0.926667   0.961039   0.795699  0.870588  0.935120\n",
       "2  Random Forest  Gap (%)  3.916667   1.317307  11.827957  7.254630  6.279544"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (Gradient Boosting) =====\n",
      "Best Hyperparameter: {'subsample': 0.6, 'n_estimators': np.int64(150), 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 2, 'learning_rate': np.float64(0.1388888888888889)}\n",
      "Best F1 Score : 0.8822982631310863\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.962536</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.955577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.933120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.051071</td>\n",
       "      <td>8.064516</td>\n",
       "      <td>4.534722</td>\n",
       "      <td>2.245663</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  Gradient Boosting    Train  0.957500   0.962536  0.897849  0.929068   \n",
       "1  Gradient Boosting     Test  0.933333   0.962025  0.817204  0.883721   \n",
       "2  Gradient Boosting  Gap (%)  2.416667   0.051071  8.064516  4.534722   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.955577  \n",
       "1  0.933120  \n",
       "2  2.245663  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning (XGBoost) =====\n",
      "Best Hyperparameter: {'subsample': 0.6, 'n_estimators': np.int64(500), 'max_depth': 2, 'learning_rate': np.float64(0.3), 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "Best F1 Score : 0.8960012698085889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.946313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.937432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.956727</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>3.202546</td>\n",
       "      <td>0.888103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Dataset  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "0  XGBoost    Train  0.956667   0.965116  0.892473  0.927374  0.946313\n",
       "1  XGBoost     Test  0.940000   0.974684  0.827957  0.895349  0.937432\n",
       "2  XGBoost  Gap (%)  1.666667  -0.956727  6.451613  3.202546  0.888103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ Final Comparison ================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.965833</td>\n",
       "      <td>0.974212</td>\n",
       "      <td>0.913978</td>\n",
       "      <td>0.943135</td>\n",
       "      <td>0.997916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.795699</td>\n",
       "      <td>0.870588</td>\n",
       "      <td>0.935120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>1.317307</td>\n",
       "      <td>11.827957</td>\n",
       "      <td>7.254630</td>\n",
       "      <td>6.279544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.957500</td>\n",
       "      <td>0.962536</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.929068</td>\n",
       "      <td>0.955577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.962025</td>\n",
       "      <td>0.817204</td>\n",
       "      <td>0.883721</td>\n",
       "      <td>0.933120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>2.416667</td>\n",
       "      <td>0.051071</td>\n",
       "      <td>8.064516</td>\n",
       "      <td>4.534722</td>\n",
       "      <td>2.245663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.946313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.937432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.956727</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>3.202546</td>\n",
       "      <td>0.888103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Model  Dataset  Accuracy  Precision     Recall  F1-Score  \\\n",
       "0      Random Forest    Train  0.965833   0.974212   0.913978  0.943135   \n",
       "1      Random Forest     Test  0.926667   0.961039   0.795699  0.870588   \n",
       "2      Random Forest  Gap (%)  3.916667   1.317307  11.827957  7.254630   \n",
       "3  Gradient Boosting    Train  0.957500   0.962536   0.897849  0.929068   \n",
       "4  Gradient Boosting     Test  0.933333   0.962025   0.817204  0.883721   \n",
       "5  Gradient Boosting  Gap (%)  2.416667   0.051071   8.064516  4.534722   \n",
       "6            XGBoost    Train  0.956667   0.965116   0.892473  0.927374   \n",
       "7            XGBoost     Test  0.940000   0.974684   0.827957  0.895349   \n",
       "8            XGBoost  Gap (%)  1.666667  -0.956727   6.451613  3.202546   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.997916  \n",
       "1  0.935120  \n",
       "2  6.279544  \n",
       "3  0.955577  \n",
       "4  0.933120  \n",
       "5  2.245663  \n",
       "6  0.946313  \n",
       "7  0.937432  \n",
       "8  0.888103  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# =========================================\n",
    "# Random Forest dengan RandomizedSearchCV\n",
    "# =========================================\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "rf_param_dist = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'max_depth': [2, 5, 10, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2'],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=rf_param_dist,\n",
    "    n_iter=20,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# ✅ gunakan X_train_transformed dan X_test_transformed\n",
    "rf_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (Random Forest) =====\")\n",
    "print(\"Best Hyperparameter:\", rf_random.best_params_)\n",
    "print(\"Best F1 Score :\", rf_random.best_score_)\n",
    "\n",
    "# Evaluasi Train vs Test\n",
    "best_rf = rf_random.best_estimator_\n",
    "df_rf_eval = evaluate_train_test(best_rf, X_train_transformed, y_train,\n",
    "                                 X_test_transformed, y_test,\n",
    "                                 model_name=\"Random Forest\")\n",
    "print(\"\\nResult Model evaluation Train vs Test:\\n\")\n",
    "display(df_rf_eval)\n",
    "\n",
    "# =========================================\n",
    "# 2. Gradient Boosting\n",
    "# =========================================\n",
    "gb = GradientBoostingClassifier(random_state=42)\n",
    "gb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "gb_random = RandomizedSearchCV(\n",
    "    estimator=gb,\n",
    "    param_distributions=gb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "gb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (Gradient Boosting) =====\")\n",
    "print(\"Best Hyperparameter:\", gb_random.best_params_)\n",
    "print(\"Best F1 Score :\", gb_random.best_score_)\n",
    "\n",
    "best_gb = gb_random.best_estimator_\n",
    "df_gb_eval = evaluate_train_test(best_gb, X_train_transformed, y_train,\n",
    "                                 X_test_transformed, y_test,\n",
    "                                 model_name=\"Gradient Boosting\")\n",
    "display(df_gb_eval)\n",
    "\n",
    "# =========================================\n",
    "# 3. XGBoost\n",
    "# =========================================\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_random.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_random.best_score_)\n",
    "\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "df_xgb_eval = evaluate_train_test(best_xgb, X_train_transformed, y_train,\n",
    "                                  X_test_transformed, y_test,\n",
    "                                  model_name=\"XGBoost\")\n",
    "display(df_xgb_eval)\n",
    "\n",
    "\n",
    "# =========================================\n",
    "# Gabungkan semua hasil evaluasi jadi 1 tabel\n",
    "# =========================================\n",
    "final_results = pd.concat([df_rf_eval, df_gb_eval, df_xgb_eval], ignore_index=True)\n",
    "print(\"\\n================ Final Comparison ================\")\n",
    "display(final_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cdd4bb",
   "metadata": {},
   "source": [
    "## XGBoost memberikan hasil yang lebih baik dan stabil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "6e49bb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 30 candidates, totalling 150 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  RandomizedSearchCV (XGBoost) =====\n",
      "Best Hyperparameter: {'subsample': 0.6, 'n_estimators': np.int64(500), 'max_depth': 2, 'learning_rate': np.float64(0.3), 'gamma': 5, 'colsample_bytree': 0.8}\n",
      "Best F1 Score : 0.8960012698085889\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.956667</td>\n",
       "      <td>0.965116</td>\n",
       "      <td>0.892473</td>\n",
       "      <td>0.927374</td>\n",
       "      <td>0.946313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.974684</td>\n",
       "      <td>0.827957</td>\n",
       "      <td>0.895349</td>\n",
       "      <td>0.937432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>-0.956727</td>\n",
       "      <td>6.451613</td>\n",
       "      <td>3.202546</td>\n",
       "      <td>0.888103</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Model  Dataset  Accuracy  Precision    Recall  F1-Score   ROC-AUC\n",
       "0  XGBoost    Train  0.956667   0.965116  0.892473  0.927374  0.946313\n",
       "1  XGBoost     Test  0.940000   0.974684  0.827957  0.895349  0.937432\n",
       "2  XGBoost  Gap (%)  1.666667  -0.956727  6.451613  3.202546  0.888103"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# 3. XGBoost\n",
    "# =========================================\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "\n",
    "xgb_param_dist = {\n",
    "    'n_estimators': np.arange(100, 501, 50),\n",
    "    'learning_rate': np.linspace(0.01, 0.3, 10),\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_random = RandomizedSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_distributions=xgb_param_dist,\n",
    "    n_iter=30,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_random.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  RandomizedSearchCV (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_random.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_random.best_score_)\n",
    "\n",
    "best_xgb = xgb_random.best_estimator_\n",
    "df_xgb_eval = evaluate_train_test(best_xgb, X_train_transformed, y_train,\n",
    "                                  X_test_transformed, y_test,\n",
    "                                  model_name=\"XGBoost\")\n",
    "display(df_xgb_eval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "8867ed8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2700 candidates, totalling 13500 fits\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  GridSearchCV (XGBoost) =====\n",
      "Best Hyperparameter: {'colsample_bytree': 1.0, 'gamma': 5, 'learning_rate': 0.2, 'max_depth': 2, 'n_estimators': 300, 'subsample': 0.6}\n",
      "Best F1 Score : 0.9027462533795798\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.951667</td>\n",
       "      <td>0.961765</td>\n",
       "      <td>0.879032</td>\n",
       "      <td>0.918539</td>\n",
       "      <td>0.947426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.963415</td>\n",
       "      <td>0.849462</td>\n",
       "      <td>0.902857</td>\n",
       "      <td>0.934990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost GridSearch</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-0.164993</td>\n",
       "      <td>2.956989</td>\n",
       "      <td>1.568218</td>\n",
       "      <td>1.243604</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  XGBoost GridSearch    Train  0.951667   0.961765  0.879032  0.918539   \n",
       "1  XGBoost GridSearch     Test  0.943333   0.963415  0.849462  0.902857   \n",
       "2  XGBoost GridSearch  Gap (%)  0.833333  -0.164993  2.956989  1.568218   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.947426  \n",
       "1  0.934990  \n",
       "2  1.243604  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# XGBoost - Grid Search\n",
    "# =========================================\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb = XGBClassifier(random_state=42, eval_metric='logloss')\n",
    "\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3],\n",
    "    'max_depth': [2, 3, 5, 7],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'gamma': [0, 1, 5]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(\n",
    "    estimator=xgb,\n",
    "    param_grid=xgb_param_grid,\n",
    "    cv=5,\n",
    "    scoring='f1',\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "xgb_grid.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  GridSearchCV (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", xgb_grid.best_params_)\n",
    "print(\"Best F1 Score :\", xgb_grid.best_score_)\n",
    "\n",
    "best_xgb_grid = xgb_grid.best_estimator_\n",
    "df_xgb_eval_grid = evaluate_train_test(best_xgb_grid, X_train_transformed, y_train,\n",
    "                                       X_test_transformed, y_test,\n",
    "                                       model_name=\"XGBoost GridSearch\")\n",
    "display(df_xgb_eval_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "8532348e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 13:40:36,000] A new study created in memory with name: no-name-568afde1-ca2a-4a41-81b1-d4871cbbdb78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "030f6faa80994f0f94f3b45faffe75fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-09-14 13:40:36,167] Trial 0 finished with value: 0.8742680357004273 and parameters: {'n_estimators': 500, 'learning_rate': 0.04825388472790625, 'max_depth': 10, 'subsample': 0.737871174848975, 'colsample_bytree': 0.9126938064830441, 'gamma': 4}. Best is trial 0 with value: 0.8742680357004273.\n",
      "[I 2025-09-14 13:40:36,251] Trial 1 finished with value: 0.8131863953725927 and parameters: {'n_estimators': 200, 'learning_rate': 0.015446716482537341, 'max_depth': 6, 'subsample': 0.7021753630959444, 'colsample_bytree': 0.601296028733632, 'gamma': 1}. Best is trial 0 with value: 0.8742680357004273.\n",
      "[I 2025-09-14 13:40:36,319] Trial 2 finished with value: 0.8762559391036273 and parameters: {'n_estimators': 400, 'learning_rate': 0.088262057085941, 'max_depth': 5, 'subsample': 0.6237264384796661, 'colsample_bytree': 0.7644755407450746, 'gamma': 3}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,411] Trial 3 finished with value: 0.8586680528433595 and parameters: {'n_estimators': 350, 'learning_rate': 0.05837853447434936, 'max_depth': 5, 'subsample': 0.9410028810974069, 'colsample_bytree': 0.6975666895402223, 'gamma': 0}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,458] Trial 4 finished with value: 0.7849391423798131 and parameters: {'n_estimators': 200, 'learning_rate': 0.012848603349274264, 'max_depth': 3, 'subsample': 0.6969510083704903, 'colsample_bytree': 0.8402959133149274, 'gamma': 1}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,517] Trial 5 finished with value: 0.8672639953698088 and parameters: {'n_estimators': 450, 'learning_rate': 0.22355019109566884, 'max_depth': 10, 'subsample': 0.8278398234149491, 'colsample_bytree': 0.7891001516873128, 'gamma': 4}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,584] Trial 6 finished with value: 0.8576531569709298 and parameters: {'n_estimators': 250, 'learning_rate': 0.07354691917016383, 'max_depth': 5, 'subsample': 0.7020200372662855, 'colsample_bytree': 0.7699601402356104, 'gamma': 0}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,643] Trial 7 finished with value: 0.8719048855469381 and parameters: {'n_estimators': 200, 'learning_rate': 0.02819878123538395, 'max_depth': 5, 'subsample': 0.887561337829037, 'colsample_bytree': 0.9227053739678677, 'gamma': 1}. Best is trial 2 with value: 0.8762559391036273.\n",
      "[I 2025-09-14 13:40:36,690] Trial 8 finished with value: 0.8835316242257159 and parameters: {'n_estimators': 300, 'learning_rate': 0.03822791133857162, 'max_depth': 3, 'subsample': 0.7121662084722751, 'colsample_bytree': 0.9742258723101334, 'gamma': 2}. Best is trial 8 with value: 0.8835316242257159.\n",
      "[I 2025-09-14 13:40:36,737] Trial 9 finished with value: 0.8692341101050337 and parameters: {'n_estimators': 300, 'learning_rate': 0.08558511957899882, 'max_depth': 8, 'subsample': 0.6975683103878868, 'colsample_bytree': 0.714634534401544, 'gamma': 4}. Best is trial 8 with value: 0.8835316242257159.\n",
      "[I 2025-09-14 13:40:36,766] Trial 10 finished with value: 0.8723837945950832 and parameters: {'n_estimators': 100, 'learning_rate': 0.19609238540865714, 'max_depth': 2, 'subsample': 0.8073139519547121, 'colsample_bytree': 0.9972714228985893, 'gamma': 2}. Best is trial 8 with value: 0.8835316242257159.\n",
      "[I 2025-09-14 13:40:36,828] Trial 11 finished with value: 0.8884251612015696 and parameters: {'n_estimators': 400, 'learning_rate': 0.12590681461903583, 'max_depth': 3, 'subsample': 0.6035803422176648, 'colsample_bytree': 0.8650931798097665, 'gamma': 3}. Best is trial 11 with value: 0.8884251612015696.\n",
      "[I 2025-09-14 13:40:36,892] Trial 12 finished with value: 0.8837002624446006 and parameters: {'n_estimators': 350, 'learning_rate': 0.1499578865716198, 'max_depth': 3, 'subsample': 0.6016259076128677, 'colsample_bytree': 0.984805032185189, 'gamma': 3}. Best is trial 11 with value: 0.8884251612015696.\n",
      "[I 2025-09-14 13:40:36,953] Trial 13 finished with value: 0.8986452722831058 and parameters: {'n_estimators': 450, 'learning_rate': 0.13693319461092693, 'max_depth': 2, 'subsample': 0.601499847262896, 'colsample_bytree': 0.8598832136909549, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,017] Trial 14 finished with value: 0.8891879833371352 and parameters: {'n_estimators': 500, 'learning_rate': 0.1329079403321285, 'max_depth': 2, 'subsample': 0.6427698089543055, 'colsample_bytree': 0.8902421006811532, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,079] Trial 15 finished with value: 0.8804118226154316 and parameters: {'n_estimators': 500, 'learning_rate': 0.29505838581213956, 'max_depth': 2, 'subsample': 0.6537865164955506, 'colsample_bytree': 0.8651828702442202, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,141] Trial 16 finished with value: 0.8648479958767409 and parameters: {'n_estimators': 450, 'learning_rate': 0.1321214552777912, 'max_depth': 7, 'subsample': 0.6635517047142947, 'colsample_bytree': 0.9159528661072753, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,214] Trial 17 finished with value: 0.8720451607734313 and parameters: {'n_estimators': 500, 'learning_rate': 0.11007032112785178, 'max_depth': 4, 'subsample': 0.7533270743255899, 'colsample_bytree': 0.828883709332861, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,278] Trial 18 finished with value: 0.8951210679550166 and parameters: {'n_estimators': 450, 'learning_rate': 0.1859117844934471, 'max_depth': 2, 'subsample': 0.6510515821004992, 'colsample_bytree': 0.9046235782323262, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,328] Trial 19 finished with value: 0.8544424960661463 and parameters: {'n_estimators': 400, 'learning_rate': 0.2948903264585208, 'max_depth': 4, 'subsample': 0.8581836068165563, 'colsample_bytree': 0.9453059880204939, 'gamma': 4}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,391] Trial 20 finished with value: 0.8672553112394595 and parameters: {'n_estimators': 450, 'learning_rate': 0.18209829635273972, 'max_depth': 7, 'subsample': 0.7610993146152834, 'colsample_bytree': 0.8186249843709179, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,451] Trial 21 finished with value: 0.8827948434541852 and parameters: {'n_estimators': 450, 'learning_rate': 0.17001476571246454, 'max_depth': 2, 'subsample': 0.6608795235327124, 'colsample_bytree': 0.8811204350575716, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,515] Trial 22 finished with value: 0.888715080721305 and parameters: {'n_estimators': 500, 'learning_rate': 0.10276188607228189, 'max_depth': 2, 'subsample': 0.6424257753566078, 'colsample_bytree': 0.8871215720128851, 'gamma': 4}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,565] Trial 23 finished with value: 0.8740417390885025 and parameters: {'n_estimators': 400, 'learning_rate': 0.23003375079041355, 'max_depth': 4, 'subsample': 0.6337136310242129, 'colsample_bytree': 0.9434764855200402, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,617] Trial 24 finished with value: 0.8797696691447676 and parameters: {'n_estimators': 350, 'learning_rate': 0.0654063340356149, 'max_depth': 2, 'subsample': 0.6756551949129675, 'colsample_bytree': 0.8962564158705322, 'gamma': 4}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,679] Trial 25 finished with value: 0.8753936069904917 and parameters: {'n_estimators': 450, 'learning_rate': 0.13572766115356283, 'max_depth': 3, 'subsample': 0.621825946120618, 'colsample_bytree': 0.8519583118942342, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,762] Trial 26 finished with value: 0.8520295758646004 and parameters: {'n_estimators': 500, 'learning_rate': 0.021122582985490704, 'max_depth': 4, 'subsample': 0.9855086568568614, 'colsample_bytree': 0.9516988124327965, 'gamma': 4}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,792] Trial 27 finished with value: 0.8765492063563002 and parameters: {'n_estimators': 100, 'learning_rate': 0.24719414883194496, 'max_depth': 2, 'subsample': 0.7711298497410618, 'colsample_bytree': 0.7958951693536015, 'gamma': 5}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,876] Trial 28 finished with value: 0.87818405258407 and parameters: {'n_estimators': 450, 'learning_rate': 0.0403632508730885, 'max_depth': 3, 'subsample': 0.7273940019222067, 'colsample_bytree': 0.7385843300893415, 'gamma': 3}. Best is trial 13 with value: 0.8986452722831058.\n",
      "[I 2025-09-14 13:40:37,959] Trial 29 finished with value: 0.8670029950631022 and parameters: {'n_estimators': 500, 'learning_rate': 0.045631482893675114, 'max_depth': 10, 'subsample': 0.6740422055130022, 'colsample_bytree': 0.9129415549383367, 'gamma': 4}. Best is trial 13 with value: 0.8986452722831058.\n",
      "========================================\n",
      "===== Hasil Hyperparameter Tuning  Bayesian Optimization (XGBoost) =====\n",
      "Best Hyperparameter: {'n_estimators': 450, 'learning_rate': 0.13693319461092693, 'max_depth': 2, 'subsample': 0.601499847262896, 'colsample_bytree': 0.8598832136909549, 'gamma': 5}\n",
      "Best F1 Score : 0.8986452722831058\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>ROC-AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Train</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.965318</td>\n",
       "      <td>0.897849</td>\n",
       "      <td>0.930362</td>\n",
       "      <td>0.945870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Test</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.975610</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.934886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>XGBoost Bayesian</td>\n",
       "      <td>Gap (%)</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>-1.029184</td>\n",
       "      <td>3.763441</td>\n",
       "      <td>1.607640</td>\n",
       "      <td>1.098320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model  Dataset  Accuracy  Precision    Recall  F1-Score  \\\n",
       "0  XGBoost Bayesian    Train  0.958333   0.965318  0.897849  0.930362   \n",
       "1  XGBoost Bayesian     Test  0.950000   0.975610  0.860215  0.914286   \n",
       "2  XGBoost Bayesian  Gap (%)  0.833333  -1.029184  3.763441  1.607640   \n",
       "\n",
       "    ROC-AUC  \n",
       "0  0.945870  \n",
       "1  0.934886  \n",
       "2  1.098320  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================================\n",
    "# XGBoost - Bayesian Optimization dengan Optuna\n",
    "# =========================================\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500, step=50),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_int('gamma', 0, 5),\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss',\n",
    "        'use_label_encoder': False\n",
    "    }\n",
    "\n",
    "    model = XGBClassifier(**params)\n",
    "    scores = cross_val_score(model, X_train_transformed, y_train, cv=5, scoring='f1', n_jobs=-1)\n",
    "    return scores.mean()\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=30, show_progress_bar=True)\n",
    "\n",
    "print(\"=\"*40)\n",
    "print(\"===== Hasil Hyperparameter Tuning  Bayesian Optimization (XGBoost) =====\")\n",
    "print(\"Best Hyperparameter:\", study.best_trial.params)\n",
    "print(\"Best F1 Score :\", study.best_value)\n",
    "\n",
    "best_xgb_bayes = XGBClassifier(**study.best_trial.params)\n",
    "best_xgb_bayes.fit(X_train_transformed, y_train)\n",
    "\n",
    "df_xgb_eval_bayes = evaluate_train_test(best_xgb_bayes, X_train_transformed, y_train,\n",
    "                                        X_test_transformed, y_test,\n",
    "                                        model_name=\"XGBoost Bayesian\")\n",
    "display(df_xgb_eval_bayes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d348754",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "acd97179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model terbaik berhasil disimpan di file 'best_xgboost_model.pkl'\n"
     ]
    }
   ],
   "source": [
    "model_filename = 'best_xgboost_model.pkl'\n",
    "joblib.dump(best_xgb, model_filename)\n",
    "print(f\"\\nModel terbaik berhasil disimpan di file '{model_filename}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "475386ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model terbaik berhasil disimpan di file \n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_xgb, 'best_xgboost_model.joblib')\n",
    "print(f\"\\nModel terbaik berhasil disimpan di file \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "6856963e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    best_xgboost_model = joblib.load('best_xgboost_model.pkl')\n",
    "    print(\"Model berhasil dimuat.\")\n",
    "except FileNotFoundError:\n",
    "    print(\"File 'best_xgboost_model.pkl' tidak ditemukan. Pastikan path sudah benar.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "676cf363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediksi berhasil dilakukan.\n"
     ]
    }
   ],
   "source": [
    "y_pred = best_xgboost_model.predict(X_test_transformed)\n",
    "print(\"Prediksi berhasil dilakukan.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "cdab4d2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      "[[205   2]\n",
      " [ 16  77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Hitung confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Tampilkan visualisasi confusion matrix\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=best_xgboost_model.classes_)\n",
    "disp.plot()\n",
    "\n",
    "# Tambahkan judul dan tampilkan plot\n",
    "plt.title('Confusion Matrix for Best XGBoost Model')\n",
    "plt.show()\n",
    "\n",
    "# Jika ingin melihat angkanya saja\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd713e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latihan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
